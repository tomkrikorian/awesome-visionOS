# Table of Contents
- [Communities](#communities)
- [Online Courses](#online-courses)
- [AI Tools](#ai-tools)
  * [GPTs](#gpts)
  * [Code Completion](#code-completion)
- [From Apple](#from-apple)
  * [WWDC](#wwdc)
    + [2023](#2023)
    + [2024](#2024)
  * [Samples](#samples)
- [Libraries](#libraries)
  * [SwiftUI](#swiftui)
  * [RealityKit](#realitykit)
  * [ARKit](#arkit)
  * [ShaderGraph](#shadergraph)
  * [Metal](#metal)
  * [Media](#media)
  * [Maps](#maps)
  * [IAP](#iap)
  * [Database](#database)
  * [AI](#ai)
  * [Testing](#testing)
- [Tools](#tools)
- [Gists](#gists)
- [Projects](#projects)
  * [Apps](#apps)
  * [Examples](#examples)
- [Articles](#articles)
  * [Media](#media-1)

# Communities
- [visionOS Developer Group on LinkedIn](https://www.linkedin.com/groups/12922559/)
- [/r/VisionPro](https://www.reddit.com/r/VisionPro/)
- [Vision Pro Discord](https://discord.com/invite/yRJmAhAQvX)
- [Apple Vision Pro Community on X](https://x.com/i/communities/1745863162396557748/)

# Online Courses
- [Apple Vision Pro Master Class](https://xrbootcamp.com/apple-vision-pro-masterclass/) Learn to create Vision Pro Apps with Swift.
- [Become a visionOS Specialist](https://www.kodeco.com/ios/programs/visionos-specialist) Craft groundbreaking 3D experiences for the future of visionOS.

# AI Tools
## GPTs
- [visionOS Assist](https://chatgpt.com/g/g-gqbgzzw40-visionos-assist) visionOS Assist provides you with up-to-date answers to your questions about visionOS 2 development.
- [VisionOS Copilot](https://chatgpt.com/g/g-kiQkZwZMF-visionos-copilot) Built to assist with building apps, this gpt is equipped with resources on VisionPro and VisionOS.
- [iOS & visionOS App Builder](https://chatgpt.com/g/g-Cw3y7bSRO-ios-visionos-app-builder) Expert Swift coder for iOS, iPadOS, and visionOS apps. GPT has been loaded with visionOS & RealityKit documentation.
- [visionOS Dev](https://chatgpt.com/g/g-GbfBtRzZo-visionos-dev) Apple Vision Pro App Generator.
- [VisionOS Developer](https://chatgpt.com/g/g-N6cjeP6IK-visionos-developer) VisionOS and Apple Vision Pro assistant and project generator, trained with the latest knowledge and docs. Write clean code and become a much faster developer.
## Code Completion
- [CopilotForXcode](https://github.com/intitni/CopilotForXcode) The missing GitHub Copilot, Codeium and ChatGPT Xcode Source Editor Extension.

# From Apple 
## WWDC
### 2023
- [Get started with building apps for spatial computing](https://developer.apple.com/videos/play/wwdc2023/10260/)
- [Meet Safari for spatial computing](https://developer.apple.com/videos/play/wwdc2023/10279/)
- [Develop your first immersive app](https://developer.apple.com/videos/play/wwdc2023/10203/)
- [Meet SwiftUI for spatial computing](https://developer.apple.com/videos/play/wwdc2023/10109/)
- [Build great games for spatial computing](https://developer.apple.com/videos/play/wwdc2023/10096/)
- [Design for spatial user interfaces](https://developer.apple.com/videos/play/wwdc2023/10076/)
- [Design for spatial input](https://developer.apple.com/videos/play/wwdc2023/10073/)
- [Principles of spatial design](https://developer.apple.com/videos/play/wwdc2023/10072/)
- [Meet UIKit for spatial computing](https://developer.apple.com/videos/play/wwdc2023/111215/)
- [Build spatial SharePlay experiences](https://developer.apple.com/videos/play/wwdc2023/10087/)
- [Discover Quick Look for spatial computing](https://developer.apple.com/videos/play/wwdc2023/10085/)
- [Enhance your spatial computing app with RealityKit](https://developer.apple.com/videos/play/wwdc2023/10081/)
- [Evolve your ARKit app for spatial experiences](https://developer.apple.com/videos/play/wwdc2023/10091/)
- [Explore materials in Reality Composer Pro](https://developer.apple.com/videos/play/wwdc2023/10202/)
- [Explore rendering for spatial computing](https://developer.apple.com/videos/play/wwdc2023/10095/)
- [Meet ARKit for spatial computing](https://developer.apple.com/videos/play/wwdc2023/10082/)
- [Take SwiftUI to the next dimension](https://developer.apple.com/videos/play/wwdc2023/10113/)
- [Work with Reality Composer Pro content in Xcode](https://developer.apple.com/videos/play/wwdc2023/10273/)
- [Explore enhancements to RoomPlan](https://developer.apple.com/videos/play/wwdc2023/10192/)
- [Meet Object Capture for iOS](https://developer.apple.com/videos/play/wwdc2023/10191/)

### 2024
- [Build compelling spatial photo and video experiences](https://developer.apple.com/videos/play/wwdc2024-10166)
- [Compose interactive 3D content in Reality Composer Pro](https://developer.apple.com/videos/play/wwdc2024-10102)
- [Create enhanced spatial computing experiences with ARKit](https://developer.apple.com/videos/play/wwdc2024-10100)
- [Design great visionOS apps](https://developer.apple.com/videos/play/wwdc2024-10086)
- [Discover RealityKit APIs for iOS, macOS and visionOS](https://developer.apple.com/videos/play/wwdc2024-10103)
- [Enhance your spatial computing app with RealityKit audio](https://developer.apple.com/videos/play/wwdc2024-111801)
- [Explore multiview video playback in visionOS](https://developer.apple.com/videos/play/wwdc2024-10116)
- [Explore object tracking for visionOS](https://developer.apple.com/videos/play/wwdc2024-10101)
- [Introducing enterprise APIs for visionOS](https://developer.apple.com/videos/play/wwdc2024-10139)
- [Whatâ€™s new in SwiftUI](https://developer.apple.com/videos/play/wwdc2024-10144)
- [Build a spatial drawing app with RealityKit](https://developer.apple.com/videos/play/wwdc2024-10104)
- [Create custom environments for your immersive apps in visionOS](https://developer.apple.com/videos/play/wwdc2024-10087)
- [Dive deep into volumes and immersive spaces](https://developer.apple.com/videos/play/wwdc2024-10153)
- [Enhance the immersion of media viewing in custom environments](https://developer.apple.com/videos/play/wwdc2024-10115)
- [Explore game input in visionOS](https://developer.apple.com/videos/play/wwdc2024-10094)
- [Meet TabletopKit for visionOS](https://developer.apple.com/videos/play/wwdc2024-10091)
- [Optimize for the spatial web](https://developer.apple.com/videos/play/wwdc2024-10065)
- [Render Metal with passthrough in visionOS](https://developer.apple.com/videos/play/wwdc2024-10092)
- [Work with windows in SwiftUI](https://developer.apple.com/videos/play/wwdc2024-10149)
- [Break into the RealityKit debugger](https://developer.apple.com/videos/play/wwdc2024-10172)
- [Bring your iOS or iPadOS game to visionOS](https://developer.apple.com/videos/play/wwdc2024-10093)
- [Build immersive web experiences with WebXR](https://developer.apple.com/videos/play/wwdc2024-10066)
- [Create custom hover effects in visionOS](https://developer.apple.com/videos/play/wwdc2024-10152)
- [Design interactive experiences for visionOS](https://developer.apple.com/videos/play/wwdc2024-10096)
- [Discover area mode for Object Capture](https://developer.apple.com/videos/play/wwdc2024-10107)
- [Get started with HealthKit in visionOS](https://developer.apple.com/videos/play/wwdc2024-10083)
- [Optimize your 3D assets for spatial computing](https://developer.apple.com/videos/play/wwdc2024-10186)
- [Customize spatial Persona templates in SharePlay](https://developer.apple.com/videos/play/wwdc2024-10201)
- [Whatâ€™s new in Quick Look for visionOS](https://developer.apple.com/videos/play/wwdc2024-10105)

## Samples 
- [Hello World](https://developer.apple.com/documentation/visionos/world) Use windows, volumes, and immersive spaces to teach people about the Earth.
- [Destination Video](https://developer.apple.com/documentation/visionos/destination-video) Leverage 3D video and Spatial Audio to deliver an immersive experience.
- [Happy Beam](https://developer.apple.com/documentation/visionos/happybeam) Leverage a Full Space to create a fun game using ARKit.
- [Diorama](https://developer.apple.com/documentation/visionos/diorama) Design scenes for your visionOS app using Reality Composer Pro.
- [Swift Splash](https://developer.apple.com/documentation/visionos/swift-splash) Use RealityKit to create an interactive ride in visionOS.
- [Incorporating real-world surroundings in an immersive experience](https://developer.apple.com/documentation/visionos/incorporating-real-world-surroundings-in-an-immersive-experience) Create an immersive experience by making your appâ€™s content respond to the local shape of the world.
- [Placing content on detected planes
](https://developer.apple.com/documentation/visionos/placing-content-on-detected-planes) Detect horizontal surfaces like tables and floors, as well as vertical planes like walls and doors.
- [Tracking specific points in world space
](https://developer.apple.com/documentation/visionos/tracking-points-in-world-space) Retrieve the position and orientation of anchors your app stores in ARKit.
- [Converting side-by-side 3D video to multiview HEVC](https://developer.apple.com/documentation/avfoundation/media_reading_and_writing/converting_side-by-side_3d_video_to_multiview_hevc) Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format.
- [Construct an immersive environment for visionOS](https://developer.apple.com/documentation/realitykit/construct-an-immersive-environment-for-visionos) Build efficient custom worlds for your app.
- [Transforming RealityKit entities using gestures](https://developer.apple.com/documentation/realitykit/transforming-realitykit-entities-with-gestures) Build a RealityKit component to support standard visionOS gestures on any entity.
- [Simulating physics with collisions in your visionOS app](https://developer.apple.com/documentation/realitykit/simulating-physics-with-collisions-in-your-visionos-app) Create entities that behave and react like physical objects in a RealityKit view.
- [Simulating particles in your visionOS app](https://developer.apple.com/documentation/realitykit/simulating-particles-in-your-visionos-app) Add a range of visual effects to a RealityKit view by attaching a particle emitter component to an entity.
- [BOT-anist](https://developer.apple.com/documentation/visionOS/BOT-anist) Build a multiplatform app that uses windows, volumes, and animations to create a robot botanistâ€™s greenhouse.
- [Building an immersive media viewing experience](https://developer.apple.com/documentation/visionos/building-an-immersive-media-viewing-experience) Add a deeper level of immersion to media playback in your app with RealityKit and Reality Composer Pro.
- [Enabling video reflections in an immersive environment](https://developer.apple.com/documentation/visionos/enabling-video-reflections-in-an-immersive-environment) Create a more immersive experience by adding video reflections in a custom environment.
- [Exploring object tracking with ARKit](https://developer.apple.com/documentation/visionos/exploring_object_tracking_with_arkit) Find and track real-world objects in visionOS using reference objects trained with Create ML.
- [Composing interactive 3D content with RealityKit and Reality Composer Pro](https://developer.apple.com/documentation/realitykit/composing-interactive-3d-content-with-realitykit-and-reality-composer-pro) Build an interactive scene using an animation timeline.
- [Presenting an artistâ€™s scene](https://developer.apple.com/documentation/realitykit/presenting-an-artists-scene) Display a scene from Reality Composer Pro in visionOS.
- [Creating a spatial drawing app with RealityKit](https://developer.apple.com/documentation/realitykit/creating-a-spatial-drawing-app-with-realitykit) Use low-level mesh and texture APIs to achieve fast updates to a personâ€™s brush strokes by integrating RealityKit with ARKit and SwiftUI.
- [Combining 2D and 3D views in an immersive app](https://developer.apple.com/documentation/realitykit/combining-2d-and-3d-views-in-an-immersive-app) Use attachments to place 2D content relative to 3D content in an immersive space.
- [Creating a Spaceship game](https://developer.apple.com/documentation/realitykit/creating-a-spaceship-game) Build an immersive game using RealityKit audio, simulation, and rendering features.
- [Rendering a windowed game in stereo](https://developer.apple.com/documentation/realitykit/rendering-a-windowed-game-in-stereo) Bring an iOS or iPadOS game to visionOS and enhance it.
- [Building local experiences with room tracking](https://developer.apple.com/documentation/arkit/arkit_in_visionos/building_local_experiences_with_room_tracking) Use room tracking in visionOS to provide custom interactions with physical spaces.
- [Visualizing HealthKit State of Mind in visionOS](https://developer.apple.com/documentation/healthkit/visualizing_healthkit_state_of_mind_in_visionos) Learn how to incorporate HealthKit State of Mind into your app and visualize the data in visionOS.
- [Customizing spatial Persona templates](https://developer.apple.com/documentation/groupactivities/customizing-spatial-persona-templates) Arrange spatial Personas in a team-based guessing game.
- [Creating a data visualization dashboard with Swift Charts](https://developer.apple.com/documentation/charts/creating-a-data-visualization-dashboard-with-swift-charts) Visualize an entire data collection efficiently by instantiating a single vectorized plot in Swift Charts.
- [Enhancing your appâ€™s content with tab navigation](https://developer.apple.com/documentation/swiftui/enhancing-your-app-content-with-tab-navigation) Visualize an entire data collection efficiently by instantiating a single vectorized plot in Swift Charts.
- [Creating tabletop games](https://developer.apple.com/documentation/tabletopkit/tabletopkitsample) Develop a spatial board game where multiple players interact with pieces on a table.

# Libraries
## SwiftUI
- [Glur](https://github.com/joogps/Glur) A SwiftUI library that uses Metal to display efficient progressive blurs, just like the ones used by Apple.
- [SwiftUI Shimmer](https://github.com/markiv/SwiftUI-Shimmer) Shimmer is a super-light modifier that adds a shimmering effect to any SwiftUI View, for example, to show that an operation is in progress.
- [CodeEditorView](https://github.com/mchakravarty/CodeEditorView) SwiftUI code editor view for iOS, visionOS, and macOS.
- [DSWaveformImage](https://github.com/dmrschmidt/DSWaveformImage) DSWaveformImage offers a native interfaces for drawing the envelope waveform of audio data.
- [EmojiKit](https://github.com/Kankoda/EmojiKit) EmojiKit is a Swift SDK that lets you use emojis on all major Apple platforms.
## RealityKit
- [RealityGeometries](https://github.com/maxxfrazer/RealityGeometries) A collection of additional geometries ready for use in RealityKit 2+. ðŸ¥½ Vision OS/Vision Pro ready.
- [GoncharKit](https://github.com/gonchar/GoncharKit) RealityKit helper functions for visionOS.
- [PlanePlopper](https://github.com/daniloc/PlanePlopper) Easy API for Vision Pro persistent immersive object placement.
## ARKit
- [FindSurface](https://github.com/CurvSurf/FindSurface-visionOS) FindSurface is a software library that extracts 3D geometric information from point cloud data.
## ShaderGraph
- [ShaderGraphCoder](https://github.com/praeclarum/ShaderGraphCoder) Write RealityKit shaders using Swift.
## Metal
- [swifty-creatives](https://github.com/yukiny0811/swifty-creatives) Creative coding framework for Swift. Built on Apple's Metal. Inspired by Processing. Supports visionOS.
## Media
- [KSPlayer](https://github.com/kingslay/KSPlayer) A video player for iOSã€macOSã€tvOSã€visionOS , based on AVPlayer and FFmpeg, support the horizontal, vertical screen. support adjust volume, brightness and seek by slide, support subtitles.
- [HaishinKit.swift](https://github.com/shogo4405/HaishinKit.swift) Camera and Microphone streaming library via RTMP and SRT.
## Maps
- [Mapbox](https://docs.mapbox.com/ios/maps/api/11.2.0-beta.1/documentation/mapboxmaps/work-with-visionos/) The Mapbox Maps SDK is a library for embedding highly customized maps.
## IAP
- [RevenueCat Purchases](https://github.com/RevenueCat/purchases-ios) In-app purchases and subscriptions made easy.
- [Flare](https://github.com/space-code/flare) In-app purchases and subscriptions made easy.
## Database
- [Firebase](https://github.com/firebase/firebase-ios-sdk) Firebase SDK for Apple App Development.
## AI
- [MLX](https://github.com/ml-explore/mlx-swift) Swift API for MLX, An array framework for Apple silicon.
- [LLM.swift](https://github.com/eastriverlee/LLM.swift) LLM.swift is a simple and readable library that allows you to interact with large language models locally with ease.
## Testing
- [MockingKit](https://github.com/danielsaidi/MockingKit) MockingKit is a Swift SDK that lets you easily mock protocols and classes.
# Tools
- [reality-check](https://github.com/ml-opensource/reality-check) RealityCheck: an open-source Mac app for streamlined debugging and real-time preview of AR projects built with RealityKit.
- [Spatial](https://blog.mikeswanson.com/spatial/) Spatial is a free macOS command-line tool to process MV-HEVC video files (currently produced by iPhone 15 Pro and Apple Vision Pro) and spatial photos.

# Gists
- [View+WindowGeometryPreferences.swift](https://gist.github.com/drewolbrich/03460fc1bb71b9a821fff722f17ec977) A visionOS SwiftUI view modifier that can be used to hide a window's resize handles or to constrain a window's aspect ratio.
- [ScaledVolumeContentView.swift](https://gist.github.com/drewolbrich/ca4802c43e6e226e9cdd95a9e52118b3) An example of how to make visionOS volumes work correctly with Settings > Display > Appearance > Window Zoom.
- [Extension+ModelComponent.swift](https://gist.github.com/ynagatomo/282486fd5ea71ac455bfe952c851cf04) An extension of ModelComponent, to dump its MeshResource.Model such as positions and normals.
- [BubbleRealityView.swift](https://gist.github.com/Matt54/850540e5610a22e5bd161cf66fdae8fb) A floating bubble (morphing transparent sphere) RealityView created from a LowLevelMesh.
- [GradientTextureSphereView.swift](https://gist.github.com/Matt54/42565f55f958ccc21f1bee617be9c2f6) LowLevelMesh Sphere with programatically generated gradient texture.
# Projects
## Apps
- [PersonaChess](https://github.com/FlipByBlink/PersonaChess) Chess game with SharePlay support.
- [HandsRuler](https://github.com/FlipByBlink/HandsRuler) Measure app by hand tracking for Apple Vision Pro.
- [ALVR](https://github.com/alvr-org/alvr-visionos) Experimental visionOS client for ALVR - SteamVR on Apple Vision Pro!
## Examples
- [Terrain](https://github.com/MatthewWaller/Terrain) A small example of procedurally generating terrain using RealityKit.
- [visionOS_30Days](https://github.com/satoshi0212/visionOS_30Days) Examples implementing various visionOS features using ARKit, RealityKit, and SwiftUI through daily projects.
- [visionOS-examples](https://github.com/IvanCampos/visionOS-examples) Examples implementing various visionOS features.
- [Immersive Video Player Sample](https://github.com/morin-innovation/immersive-video-player-sample) Immersive Video Player Sample.
- [SpatialPlayer](https://github.com/mikeswanson/SpatialPlayer) An example spatial/immersive MV-HEVC video player for Apple Vision Pro
- [metal-spatial-rendering](https://github.com/metal-by-example/metal-spatial-rendering) A minimal example of rendering a fully immersive spatial experience with Metal, ARKit, and visionOS Compositing Services.
- [SpatialMetal](https://github.com/musesum/SpatialMetal) VisionOS metal with swift refactored from FullyImmersiveMetal.
- [SpatialMetal2](https://github.com/musesum/SpatialMetal2) SpatialMetal extended for multiple shaders.
- [VisionProVacuumDemo](https://github.com/gonchar/VisionProVacuumDemo) Demo project which showcases how to work with Apple Vision Pro and RealityKit, ARKit APIs.
- [HandTrackingSandbox](https://github.com/kentvchr/HandTrackingSandbox) Use of ARKit and RealityKit frameworks to make a playful sandbox, where physical environment can interact with generated virtual content.
- [Agora Quickstart](https://github.com/AgoraIO-Community/visionOS-Quickstart) Basic video call with visionOS for Apple Vision Pro. Using Agora RTC SDK.
- [SceneVisualizer](https://github.com/agg23/SceneVisualizer) A simple example to visualize the LIDAR information received by Vision Pro.
- [HandVector](https://github.com/XanderXu/HandVector) HandVector uses Cosine Similarity Algorithm to calculate the similarity of hand gestures.
- [MLX & Mistral](https://github.com/morin-innovation/mlx-swift-examples/tree/visionos-support) Example of using MLX Swift & Mistral.
- [metal-spatial-dynamic-mesh](https://github.com/metal-by-example/metal-spatial-dynamic-mesh) A demonstration of RealityKit's LowLevelMesh API.
- [Settings-visionOS](https://github.com/zhrispineda/Settings-visionOS) SwiftUI recreation of the visionOS Settings app.
- [VOClimateSpiral](https://github.com/ynagatomo/VOClimateSpiral) Very simple AR app in visionOS, that shows the climate spiral, which is known as a way to visualize global surface temperature change.
- [Procedural Generation](https://github.com/GabrielWeinbrenner/Procedural-Sandbox/tree/main) Utilizing Metal Meshbuffers to create procedurally generated meshes

# Articles
## Media
- [Immersive Video: Which camera is right?](https://medium.com/@portemantho/immersive-video-which-camera-is-right-db429042aa58)
